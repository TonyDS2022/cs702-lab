---
title: "Lab Week 4. Multi-armed Bandit (A/B Testing)"
mermaid-format: png
---

## Introduction

This week's lab explores the multi-armed bandit problem—a classic framework for balancing exploration and exploitation in sequential decision-making. You'll learn to formulate A/B tests using Thompson sampling with Bayesian inference.

> You are tasked with conducting a sequential A/B test of two interface designs ($i \in \{A, B\}$). Users perform a task using one of the interfaces, and we observe an outcome of either $x \in \{\text{Success}, \text{Failure}\}$.

For each interface design, we model the probability of a successful interaction $p_i$ using:

$$
\begin{aligned}
p_i &\sim \text{Beta}(1, 1) \\
x_i &\sim \text{Bernoulli}(p_i)
\end{aligned}
$$

## Q1. Deriving Posterior Distributions

Given the following observations, derive the posterior distributions of $p_A$ and $p_B$ for design A and design B.

- Design A: [Success, Failure, Success, Success, Failure]
- Design B: [Success, Success, Success, Failure, Success]

::: {.callout-tip title="Answer" icon=false}
Given the probabilistic model

$$
\begin{aligned}
p_i &\sim \beta(1, 1) \\
x_i &\sim \text{Bernoulli}(p_i)
\end{aligned}
$$

By conjugacy of the Beta-Bernoulli distribution, the posterior distribution is given by

$$
p_i\,|\,\text{data} \sim \beta\left(\alpha_0 + \sum x_i, \beta_0 + N - \sum x_i\right)
$$

where $\alpha_0 = 1$ and $\beta_0 = 1$ are the prior parameters.

For design A, we observe 3 Successes and 2 Failures, thus

$$
p_A\,|\,\text{data} \sim \beta(1 + 3,\,1 + 2) = \beta(4, 3).
$$

And for design B, we observe 4 Successes and 1 Failure, therefore

$$
p_B\,|\,\text{data} \sim \beta(1 + 4,\,1 + 1) = \beta(5, 2).
$$
:::


## Q2. Selecting the Next Design

Based on the posterior distributions you derived, which design would the agent more likely select for the next user? Explain your reasoning.

::: {.callout-tip title="Answer" icon=false}
We recall the Thompson Sampling algorithm in a 2-armed bandit problem as follows:

```{.pseudocode}
#| label: "Thompson Sampling"
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-line-number: true

\begin{algorithm}
\caption{Thompson Sampling}
\begin{algorithmic}
\State Initialize $\alpha_A = 1, \beta_A = 1$  \Comment{Prior for Design A}
\State Initialize $\alpha_B = 1, \beta_B = 1$  \Comment{Prior for Design B}
\For{each user $t = 1, 2, \dots, T$}
    \State Sample $\tilde{p}_A \sim \text{Beta}(\alpha_A, \beta_A)$
    \State Sample $\tilde{p}_B \sim \text{Beta}(\alpha_B, \beta_B)$
    \If{$\tilde{p}_A > \tilde{p}_B$}
        \State Select design $A$ for the current user
        \State Observe outcome $x \in \{\text{Success}, \text{Failure}\}$
        \State Update $\alpha_A \leftarrow \alpha_A + x$, $\beta_A \leftarrow \beta_A + (1-x)$
    \Else
        \State Select design $B$ for the current user
        \State Observe outcome $x \in \{\text{Success}, \text{Failure}\}$
        \State Update $\alpha_B \leftarrow \alpha_B + x$, $\beta_B \leftarrow \beta_B + (1-x)$
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}
```

The agent would recommend design A if and only if the sampled values $\tilde{p}_{A} > \tilde{p}_{B}$. We have the posterior distributions

$$
p_A \sim \text{Beta}(4, 3) \text{; and} \quad p_B \sim \text{Beta}(5, 2).
$$

It is obvious that $p_B$ will likely draw a larger sample, hence the agent is more likely to select design B.

:::

## Q3. Balancing Exploration and Exploitation

Suppose you need to conduct this A/B test with 1000 users in a sequential manner. Explain how Thompson sampling (or bandit algorithms in general) helps balance exploration and exploitation in this context.

::: {.callout-tip title="Answer" icon=false}
Thompson sampling exploits the properties of the Beta distribution to balance between exploration and exploitation.

Given an initally weakly informative prior (i.e. $\text{Beta}(1,\,1)$) for each bandits, these distributions are initialized with maximal kurtosis/uncertainty. At this stage, the algorithm is equivalent to sampling from arms with a discrete uniform probability distribution.

As samples accumulate and the posteriors get updated with $\text{Beta}(1 + \text{number of successes}, 1 + \text{number of failures})$, the distributions are less kurtotic. The arms with higher empirical rate of success will be drawn with overwhelmingly higher probabilities.
:::

## Q4. Thompson Sampling Implementation

Implement a Thompson sampling algorithm to simulate the sequential A/B test described above using NumPyro.

Requirements:

1. Initialize Beta priors for both designs A and B as Beta(1, 1)
2. For each of 1000 users:
   - Sample from the posterior distributions of $p_A$ and $p_B$
   - Select the design with the higher sampled value
   - Simulate an outcome (Success/Failure) based on the true success probabilities: $p_A = 0.4$ and $p_B = 0.6$
   - Update the posterior distribution for the selected design

After all 1000 users, report:
- The total number of times each design was selected
- The total number of successes for each design
- The final posterior distributions (alpha and beta parameters) for both designs

## Deliverable

Submit a zip file to eLearn containing:

1. Written answers to Q1–Q3 with explanations and calculations
2. NumPyro code for Q4 implementing Thompson sampling algorithm
