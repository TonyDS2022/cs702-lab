---
title: "Lab Week 4. Multi-armed Bandit (A/B Testing)"
mermaid-format: png
---

## Introduction

This week's lab explores the multi-armed bandit problem—a classic framework for balancing exploration and exploitation in sequential decision-making. You'll learn to formulate A/B tests using Thompson sampling with Bayesian inference.

> You are tasked with conducting a sequential A/B test of two interface designs ($i \in \{A, B\}$). Users perform a task using one of the interfaces, and we observe an outcome of either $x \in \{\text{Success}, \text{Failure}\}$.

For each interface design, we model the probability of a successful interaction $p_i$ using:

$$
\begin{aligned}
p_i &\sim \text{Beta}(1, 1) \\
x_i &\sim \text{Bernoulli}(p_i)
\end{aligned}
$$

## Q1. Deriving Posterior Distributions

Given the following observations, derive the posterior distributions of $p_A$ and $p_B$ for design A and design B.

- Design A: [Success, Failure, Success, Success, Failure]
- Design B: [Success, Success, Success, Failure, Success]

::: {.callout-tip title="Answer" icon=false}
Given the probabilistic model

$$
\begin{aligned}
p_i &\sim \beta(1, 1) \\
x_i &\sim \text{Bernoulli}(p_i)
\end{aligned}
$$

By conjugacy of the Beta-Bernoulli distribution, the posterior distribution is given by

$$
p_i\,|\,\text{data} \sim \beta\left(\alpha_0 + \sum x_i, \beta_0 + N - \sum x_i\right)
$$

where $\alpha_0 = 1$ and $\beta_0 = 1$ are the prior parameters.

For design A, we observe 3 Successes and 2 Failures, thus

$$
p_A\,|\,\text{data} \sim \beta(1 + 3,\,1 + 2) = \beta(4, 3).
$$

And for design B, we observe 4 Successes and 1 Failure, therefore

$$
p_B\,|\,\text{data} \sim \beta(1 + 4,\,1 + 1) = \beta(5, 2).
$$
:::


## Q2. Selecting the Next Design

Based on the posterior distributions you derived, which design would the agent more likely select for the next user? Explain your reasoning.

::: {.callout-tip title="Answer" icon=false}
We recall the Thompson Sampling algorithm in a 2-armed bandit problem as follows:

```{.pseudocode}
#| label: "Thompson Sampling"
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-line-number: true

\begin{algorithm}
\caption{Thompson Sampling}
\begin{algorithmic}
\State Initialize $\alpha_A = 1, \beta_A = 1$  \Comment{Prior for Design A}
\State Initialize $\alpha_B = 1, \beta_B = 1$  \Comment{Prior for Design B}
\For{each user $t = 1, 2, \dots, T$}
    \State Sample $\tilde{p}_A \sim \text{Beta}(\alpha_A, \beta_A)$
    \State Sample $\tilde{p}_B \sim \text{Beta}(\alpha_B, \beta_B)$
    \If{$\tilde{p}_A > \tilde{p}_B$}
        \State Select design $A$ for the current user
        \State Observe outcome $x \in \{\text{Success}, \text{Failure}\}$
        \State Update $\alpha_A \leftarrow \alpha_A + x$, $\beta_A \leftarrow \beta_A + (1-x)$
    \Else
        \State Select design $B$ for the current user
        \State Observe outcome $x \in \{\text{Success}, \text{Failure}\}$
        \State Update $\alpha_B \leftarrow \alpha_B + x$, $\beta_B \leftarrow \beta_B + (1-x)$
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}
```

The agent would recommend design A if and only if the sampled values $\tilde{p}_{A} > \tilde{p}_{B}$. We have the posterior distributions

$$
p_A \sim \text{Beta}(4, 3) \text{; and} \quad p_B \sim \text{Beta}(5, 2).
$$

It is obvious that $p_B$ will likely draw a larger sample, hence the agent is more likely to select design B.

:::

## Q3. Balancing Exploration and Exploitation

Suppose you need to conduct this A/B test with 1000 users in a sequential manner. Explain how Thompson sampling (or bandit algorithms in general) helps balance exploration and exploitation in this context.

::: {.callout-tip title="Answer" icon=false}
Thompson sampling exploits the properties of the Beta distribution to balance between exploration and exploitation.

Given an initally weakly informative prior (i.e. $\text{Beta}(1,\,1)$) for each bandits, these distributions are initialized with maximal kurtosis/uncertainty. At this stage, the algorithm is equivalent to sampling from arms with a discrete uniform probability distribution.

As samples accumulate and the posteriors get updated with $\text{Beta}(1 + \text{number of successes}, 1 + \text{number of failures})$, the distributions are less kurtotic. The arms with higher empirical rate of success will be drawn with overwhelmingly higher probabilities.
:::

## Q4. Thompson Sampling Implementation

Implement a Thompson sampling algorithm to simulate the sequential A/B test described above using NumPyro.

Requirements:

1. Initialize Beta priors for both designs A and B as Beta(1, 1)
2. For each of 1000 users:
   - Sample from the posterior distributions of $p_A$ and $p_B$
   - Select the design with the higher sampled value
   - Simulate an outcome (Success/Failure) based on the true success probabilities: $p_A = 0.4$ and $p_B = 0.6$
   - Update the posterior distribution for the selected design

After all 1000 users, report:
- The total number of times each design was selected
- The total number of successes for each design
- The final posterior distributions (alpha and beta parameters) for both designs

::: {.callout-tip title="Answer" icon=false}

```{python}
#| eval: true
#| output: true

import jax
import jax.numpy as jnp
import numpy as np
import numpyro.distributions as dist

# --- Configuration ---
N_USERS = 1000
P_A_TRUE = 0.4
P_B_TRUE = 0.6

# --- Thompson Sampling Simulation ---
key = jax.random.PRNGKey(42)

alpha_A, beta_A = 1.0, 1.0
alpha_B, beta_B = 1.0, 1.0

# tracking arrays
selections = []          # 'A' or 'B'
outcomes = []            # 1 (success) or 0 (failure)
cum_select_A = np.zeros(N_USERS)
cum_select_B = np.zeros(N_USERS)
cum_regret = np.zeros(N_USERS)

count_A, count_B = 0, 0
success_A, success_B = 0, 0
regret = 0.0

for t in range(N_USERS):
    key, key_a, key_b, key_outcome = jax.random.split(key, 4)

    p_a_sample = float(dist.Beta(alpha_A, beta_A).sample(key_a))
    p_b_sample = float(dist.Beta(alpha_B, beta_B).sample(key_b))

    if p_a_sample > p_b_sample:
        chosen = "A"
        count_A += 1
        outcome = int(jax.random.bernoulli(key_outcome, P_A_TRUE))
        if outcome:
            success_A += 1
        alpha_A += outcome
        beta_A += 1 - outcome
        regret += P_B_TRUE - P_A_TRUE
    else:
        chosen = "B"
        count_B += 1
        outcome = int(jax.random.bernoulli(key_outcome, P_B_TRUE))
        if outcome:
            success_B += 1
        alpha_B += outcome
        beta_B += 1 - outcome
        # no regret when choosing the optimal arm

    selections.append(chosen)
    outcomes.append(outcome)
    cum_select_A[t] = count_A
    cum_select_B[t] = count_B
    cum_regret[t] = regret

# --- Summary ---
print("=== Thompson Sampling Results (1000 users) ===\n")
print(f"Design A:  selected {count_A:>4d} times,  {success_A:>4d} successes")
print(f"Design B:  selected {count_B:>4d} times,  {success_B:>4d} successes")
print(f"\nFinal posteriors:")
print(f"  p_A | data  ~  Beta({alpha_A:.0f}, {beta_A:.0f})")
print(f"  p_B | data  ~  Beta({alpha_B:.0f}, {beta_B:.0f})")

# Pre-compute shared data for plots
users = np.arange(1, N_USERS + 1)
prop_B = cum_select_B / users

x_pdf = np.linspace(0, 1, 300)
prior_pdf = np.array(dist.Beta(1.0, 1.0).log_prob(jnp.linspace(0.001, 0.999, 300)))
prior_pdf = np.exp(prior_pdf)
post_A_pdf = np.exp(np.array(
    dist.Beta(alpha_A, beta_A).log_prob(jnp.linspace(0.001, 0.999, 300))
))
post_B_pdf = np.exp(np.array(
    dist.Beta(alpha_B, beta_B).log_prob(jnp.linspace(0.001, 0.999, 300))
))
```

::: {.content-visible when-format="html"}
```{python}
#| eval: true
#| output: true
#| label: fig-thompson-sampling-html
#| fig-cap: "Thompson Sampling simulation results"

import plotly.graph_objects as go
from plotly.subplots import make_subplots

fig = make_subplots(
    rows=3, cols=1,
    subplot_titles=(
        "Proportion of Design B Selections Over Time",
        "Final Posterior Distributions vs Prior",
        "Cumulative Regret",
    ),
    vertical_spacing=0.10,
)

# --- Panel 1: Selection proportion ---
fig.add_trace(go.Scatter(
    x=users, y=prop_B,
    mode="lines", name="Prop. selecting B",
    line=dict(color="#248DCC", width=2),
), row=1, col=1)
fig.add_hline(
    y=0.5, line_dash="dot", line_color="grey",
    annotation_text="50 %", annotation_font_color="grey",
    row=1, col=1,
)

# --- Panel 2: Posterior PDFs ---
fig.add_trace(go.Scatter(
    x=x_pdf, y=prior_pdf,
    mode="lines", name="Prior Beta(1,1)",
    line=dict(color="grey", width=1.5, dash="dash"),
), row=2, col=1)
fig.add_trace(go.Scatter(
    x=x_pdf, y=post_A_pdf,
    mode="lines", name=f"Posterior A: Beta({alpha_A:.0f},{beta_A:.0f})",
    line=dict(color="#FD730A", width=2.5),
    fill="tozeroy", fillcolor="rgba(253,115,10,0.15)",
), row=2, col=1)
fig.add_trace(go.Scatter(
    x=x_pdf, y=post_B_pdf,
    mode="lines", name=f"Posterior B: Beta({alpha_B:.0f},{beta_B:.0f})",
    line=dict(color="#67A902", width=2.5),
    fill="tozeroy", fillcolor="rgba(103,169,2,0.15)",
), row=2, col=1)
fig.add_vline(
    x=P_A_TRUE, line_dash="dot", line_color="#FD730A",
    annotation_text=f"True p_A={P_A_TRUE}",
    annotation_font_color="#FD730A",
    row=2, col=1,
)
fig.add_vline(
    x=P_B_TRUE, line_dash="dot", line_color="#67A902",
    annotation_text=f"True p_B={P_B_TRUE}",
    annotation_font_color="#67A902",
    row=2, col=1,
)

# --- Panel 3: Cumulative regret ---
fig.add_trace(go.Scatter(
    x=users, y=cum_regret,
    mode="lines", name="Cumulative regret",
    line=dict(color="#E84855", width=2),
), row=3, col=1)

# --- Layout ---
fig.update_layout(
    height=900,
    template="plotly_dark",
    paper_bgcolor="rgba(0,0,0,0)",
    plot_bgcolor="rgba(0,0,0,0)",
    font=dict(color="#fff"),
    legend=dict(font=dict(color="#fff")),
    showlegend=True,
)
fig.update_xaxes(title_text="User number", row=1, col=1)
fig.update_yaxes(title_text="Proportion", row=1, col=1)
fig.update_xaxes(title_text="p", row=2, col=1)
fig.update_yaxes(title_text="Density", row=2, col=1)
fig.update_xaxes(title_text="User number", row=3, col=1)
fig.update_yaxes(title_text="Regret", row=3, col=1)
fig.show()
```
:::

::: {.content-visible when-format="pdf"}
```{python}
#| eval: true
#| output: true
#| label: fig-thompson-sampling-pdf
#| fig-cap: "Thompson Sampling simulation results"

import matplotlib.pyplot as plt
import seaborn as sns

sns.set_theme(style="whitegrid", font_scale=1.1, rc={
    "axes.edgecolor": "#444444",
    "grid.color": "#e0e0e0",
    "grid.linestyle": "--",
    "grid.alpha": 0.4,
    "figure.facecolor": "white",
})

fig, axes = plt.subplots(3, 1, figsize=(8, 12))

# --- Panel 1: Selection proportion ---
ax = axes[0]
ax.plot(users, prop_B, color="#248DCC", linewidth=2, label="Prop. selecting B")
ax.axhline(0.5, linestyle=":", color="grey", linewidth=1)
ax.set_xlabel("User number")
ax.set_ylabel("Proportion")
ax.set_title("Proportion of Design B Selections Over Time", fontweight="bold")
ax.legend(frameon=True, fancybox=True)
sns.despine(ax=ax, left=True)

# --- Panel 2: Posterior PDFs ---
ax = axes[1]
ax.plot(x_pdf, prior_pdf, color="grey", linewidth=1.5, linestyle="--",
        label="Prior Beta(1,1)")
ax.fill_between(x_pdf, post_A_pdf, alpha=0.2, color="#FD730A")
ax.plot(x_pdf, post_A_pdf, color="#FD730A", linewidth=2.5,
        label=f"Posterior A: Beta({alpha_A:.0f},{beta_A:.0f})")
ax.fill_between(x_pdf, post_B_pdf, alpha=0.2, color="#67A902")
ax.plot(x_pdf, post_B_pdf, color="#67A902", linewidth=2.5,
        label=f"Posterior B: Beta({alpha_B:.0f},{beta_B:.0f})")
ax.axvline(P_A_TRUE, linestyle=":", color="#FD730A", linewidth=1.5)
ax.axvline(P_B_TRUE, linestyle=":", color="#67A902", linewidth=1.5)
ax.set_xlabel(r"$p$")
ax.set_ylabel("Density")
ax.set_title("Final Posterior Distributions vs Prior", fontweight="bold")
ax.legend(frameon=True, fancybox=True, fontsize=9)
sns.despine(ax=ax, left=True)

# --- Panel 3: Cumulative regret ---
ax = axes[2]
ax.plot(users, cum_regret, color="#E84855", linewidth=2, label="Cumulative regret")
ax.set_xlabel("User number")
ax.set_ylabel("Regret")
ax.set_title("Cumulative Regret", fontweight="bold")
ax.legend(frameon=True, fancybox=True)
sns.despine(ax=ax, left=True)

plt.tight_layout()
plt.show()
```
:::

:::

## Deliverable

Submit a zip file to eLearn containing:

1. Written answers to Q1–Q3 with explanations and calculations
2. NumPyro code for Q4 implementing Thompson sampling algorithm
